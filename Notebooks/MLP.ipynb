{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f073176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "current_directtory = os.getcwd()\n",
    "sys.path[0]=os.path.abspath(os.path.join(current_directtory, \"..\", \"charlm\"))\n",
    "from ngram import CharNGram\n",
    "from charlm import CharLM\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"names\"\n",
    "\n",
    "# Load data\n",
    "with open(f\"../data/input/{file}.txt\", \"r\") as f:\n",
    "#     names = list(set([i for i in f.read().splitlines()]))\n",
    "    names = f.read().splitlines()\n",
    "\n",
    "random.shuffle(names)\n",
    "\n",
    "# Calculate the indices for splitting\n",
    "total = len(names)\n",
    "train_size = int(0.8 * total)\n",
    "dev_size = int(0.1 * total)\n",
    "\n",
    "# Split the names\n",
    "names_train = names[:train_size]\n",
    "names_dev = names[train_size:train_size + dev_size]\n",
    "names_test = names[train_size + dev_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635eea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá ya no usamos cadenas de ngrams sino que usamos una representación continua de los caracteres\n",
    "# y la unidad mínima ya no es es el n-gram sino el caracter, y se hacen append de la cantidad de caracteres\n",
    "# que deseemos usar como predictor. Entonces, el universo que queremos representar es el universo de átomos (en\n",
    "# este caso caracteres). Así, la matriz que representa los inputs crece hacia la izquierda (en columnas)\n",
    "# y no hacia abajo (filas) como era en el caso de ngrams. Esto porque una cadena de strings ahora se representa\n",
    "# como una cadena de vectores embeddings (más columnas) y no como una nueva fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f98e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLM(context_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a4fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test= model.get_formatted_tensors(train = names_train,\n",
    "                                                                            dev = names_dev,\n",
    "                                                                            test = names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a4db38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 200000/200000 [04:31<00:00, 736.13it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          neurons_per_layer = [100, 100,len(model.char_universe)], \n",
    "          activations = [\"tanh\", \"tanh\", \"softmax\"], \n",
    "          batch_size_percentage = 0.01,\n",
    "          size_of_embeddings = 40, \n",
    "          epochs = 200000, \n",
    "          learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369c5870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0253448486328125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de6e985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1506335735321045"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_loss(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1641b893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.156299114227295"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_loss(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d437f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.generate_words(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charlm",
   "language": "python",
   "name": "charlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
