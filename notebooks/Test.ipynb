{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0945e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dc591",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a84939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/dog_names.txt\", \"r\") as f:\n",
    "    names = list(set([i for i in f.read().splitlines()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43095fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_train = random.sample(names, k=int(0.95*(len(names))))\n",
    "names_test = list(set(names) - set(names_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece5600",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c848d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_list(list_object, n):\n",
    "    ngrams = []\n",
    "    for element in list_object:\n",
    "        if len(element)>=n:\n",
    "            ngrams.append((\"<>\" + element[0:n-2], element[n-2]))\n",
    "            for idx in range(len(element) - n + 1):\n",
    "                ngrams.append((element[idx:idx+n-1], element[idx+n-1]))\n",
    "            ngrams.append((element[len(element)-n+1:], \"<>\"))\n",
    "    return ngrams\n",
    "\n",
    "def ngram_list_updated(list_object, n):\n",
    "    ngrams = []\n",
    "    for n_of_grams in range(2, n+1):\n",
    "        for element in list_object:\n",
    "            element = [\"<>\"] + list(element) + [\"<>\"]\n",
    "            if len(element)>=(n_of_grams-2):\n",
    "                for idx in range(len(element) - n_of_grams + 1):\n",
    "                    ngrams.append((\"\".join(element[idx:idx+n_of_grams-1]), \"\".join(element[idx+n_of_grams-1])))\n",
    "    return ngrams\n",
    "\n",
    "def ngram_count(list_ngrams):\n",
    "    ngrams_counts = {}\n",
    "    for ngram in list_ngrams:\n",
    "        if ngram in ngrams_counts:\n",
    "            ngrams_counts[ngram] += 1\n",
    "        else:\n",
    "            ngrams_counts[ngram] = 1\n",
    "    return ngrams_counts\n",
    "\n",
    "def calculate_conditional_probabilities(ngram_counts):\n",
    "    firsts = sorted(list(set([i[0] for i in ngram_counts.keys()])))\n",
    "    nexts = sorted(list(set([i[1] for i in ngram_counts.keys()])))\n",
    "    probabilities = np.zeros((len(firsts), len(nexts)))\n",
    "    for idx_f, f in enumerate(firsts):\n",
    "        for idx_n, n in enumerate(nexts):\n",
    "            probabilities[(idx_f, idx_n)] = counts.get((f, n), 0)\n",
    "    probabilities = probabilities / probabilities.sum(axis=1, keepdims=True)\n",
    "    return firsts, nexts, probabilities\n",
    "\n",
    "def generate_word(firsts, nexts, probabilites, n):\n",
    "    first_char = str(np.random.choice(nexts, size=1, replace=True, p=probabilities[firsts.index(\"<>\")])[0])\n",
    "    word = first_char\n",
    "    while True:\n",
    "        prev_ngram = word[-(n-1):] if len(word)>=(n-1) else '<>'+word\n",
    "        next_char = str(np.random.choice(nexts, size=1, replace=True, p=probabilities[firsts.index(prev_ngram)])[0])\n",
    "        if next_char == \"<>\":\n",
    "            break\n",
    "        word += next_char\n",
    "    return word\n",
    "\n",
    "def generate_words(n_words, firsts, nexts, probabilities, n):\n",
    "    words = []\n",
    "    for i in range(n_words):\n",
    "        words.append(generate_word(firsts, nexts, probabilities, n))\n",
    "    return words\n",
    "\n",
    "def calculate_perplexity(word, probabilities, n):\n",
    "    word = [\"<>\"] + list(word) + [\"<>\"]\n",
    "    predictor_grams = []\n",
    "    for idx_char, char in enumerate(word[:-1]):\n",
    "        predictor_grams.append(\"\".join(word[max(0, idx_char - (n-1) + 1):idx_char+1]))\n",
    "    perplexity = 1\n",
    "    for predictor, test in zip(predictor_grams, word[1:]):\n",
    "        try:\n",
    "            probability = float(probabilities[firsts.index(predictor)][nexts.index(test)])\n",
    "            probability = probability if probability>0 else 0.001\n",
    "        except:\n",
    "            print(f\"aaaa {predictor}\")\n",
    "            probability = 1\n",
    "        perplexity *= (probability)**(-1/len(predictor_grams))\n",
    "    return perplexity\n",
    "\n",
    "def calculate_test_set_perplexities(test_list, probabilities, n):\n",
    "    perplexities = []\n",
    "    for element in test_list:\n",
    "        perplexities.append(calculate_perplexity(element, probabilities, n))\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4b3a4",
   "metadata": {},
   "source": [
    "# Test set perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7e9ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in names_train if \"drk\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f9257f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in ngrams if (\"drk\" in i[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739d7677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<>', 'd'),\n",
       " ('d', 'r'),\n",
       " ('r', 'k'),\n",
       " ('k', 'r'),\n",
       " ('r', 'o'),\n",
       " ('o', 'm'),\n",
       " ('m', 'b'),\n",
       " ('b', 'a'),\n",
       " ('a', 'c'),\n",
       " ('c', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', '<>'),\n",
       " ('<>d', 'r'),\n",
       " ('dr', 'k'),\n",
       " ('rk', 'r'),\n",
       " ('kr', 'o'),\n",
       " ('ro', 'm'),\n",
       " ('om', 'b'),\n",
       " ('mb', 'a'),\n",
       " ('ba', 'c'),\n",
       " ('ac', 'h'),\n",
       " ('ch', 'e'),\n",
       " ('he', 'r'),\n",
       " ('er', '<>'),\n",
       " ('<>dr', 'k'),\n",
       " ('drk', 'r'),\n",
       " ('rkr', 'o'),\n",
       " ('kro', 'm'),\n",
       " ('rom', 'b'),\n",
       " ('omb', 'a'),\n",
       " ('mba', 'c'),\n",
       " ('bac', 'h'),\n",
       " ('ach', 'e'),\n",
       " ('che', 'r'),\n",
       " ('her', '<>'),\n",
       " ('<>drk', 'r'),\n",
       " ('drkr', 'o'),\n",
       " ('rkro', 'm'),\n",
       " ('krom', 'b'),\n",
       " ('romb', 'a'),\n",
       " ('omba', 'c'),\n",
       " ('mbac', 'h'),\n",
       " ('bach', 'e'),\n",
       " ('ache', 'r'),\n",
       " ('cher', '<>'),\n",
       " ('<>drkr', 'o'),\n",
       " ('drkro', 'm'),\n",
       " ('rkrom', 'b'),\n",
       " ('kromb', 'a'),\n",
       " ('romba', 'c'),\n",
       " ('ombac', 'h'),\n",
       " ('mbach', 'e'),\n",
       " ('bache', 'r'),\n",
       " ('acher', '<>')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_list_updated(['drkrombacher'], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad0ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa <>drk\n",
      "aaaa <>drkr\n",
      "aaaa drkro\n",
      "aaaa rkrom\n",
      "aaaa kromb\n",
      "aaaa romba\n",
      "aaaa ombac\n",
      "aaaa mbach\n",
      "aaaa bache\n",
      "aaaa <>kaza\n",
      "aaaa kazan\n",
      "aaaa ranki\n",
      "aaaa ankie\n",
      "aaaa <>laby\n",
      "aaaa labyr\n",
      "aaaa abyri\n",
      "aaaa byrin\n",
      "aaaa yrint\n",
      "aaaa rinth\n",
      "aaaa iboro\n",
      "aaaa shang\n",
      "aaaa hangr\n",
      "aaaa angri\n",
      "aaaa ngria\n",
      "aaaa <>nouc\n",
      "aaaa oucki\n",
      "aaaa uckia\n",
      "aaaa levit\n",
      "aaaa <>laic\n",
      "aaaa laica\n",
      "aaaa <>garp\n",
      "aaaa <>pixe\n",
      "aaaa pixel\n",
      "aaaa icita\n",
      "aaaa citas\n",
      "aaaa fuzzy\n",
      "aaaa igorn\n",
      "aaaa <>vop\n",
      "aaaa <>vopo\n",
      "aaaa <>baq\n",
      "aaaa <>baqu\n",
      "aaaa baque\n",
      "aaaa aquer\n",
      "aaaa orano\n",
      "aaaa haski\n",
      "aaaa alias\n",
      "aaaa liasa\n",
      "aaaa <>cowy\n",
      "aaaa <>frag\n",
      "aaaa fragg\n",
      "aaaa aggel\n",
      "aaaa ggels\n",
      "aaaa <>wuf\n",
      "aaaa <>wuff\n",
      "aaaa wuffi\n",
      "aaaa <>varu\n",
      "aaaa varus\n",
      "aaaa <>duce\n",
      "aaaa <>atin\n",
      "aaaa kleop\n",
      "aaaa quino\n",
      "aaaa lucya\n",
      "aaaa ucyan\n",
      "aaaa cyann\n",
      "aaaa aries\n",
      "aaaa freik\n",
      "aaaa ackso\n",
      "aaaa norda\n",
      "aaaa <>venu\n",
      "aaaa venus\n",
      "aaaa <>wilh\n",
      "aaaa wilhe\n",
      "aaaa ilhel\n",
      "aaaa lhelm\n",
      "aaaa jingl\n",
      "aaaa ingle\n",
      "aaaa ngles\n",
      "aaaa <>iku\n",
      "aaaa <>ikus\n",
      "aaaa <>pudd\n",
      "aaaa puddl\n",
      "aaaa cabar\n",
      "aaaa abare\n",
      "aaaa baret\n",
      "aaaa <>mang\n",
      "aaaa mango\n",
      "aaaa ashin\n",
      "aaaa hingt\n",
      "aaaa <>ext\n",
      "aaaa <>extr\n",
      "aaaa extra\n",
      "aaaa teren\n",
      "aaaa erenc\n",
      "aaaa <>walp\n",
      "aaaa walpu\n",
      "aaaa lpurg\n",
      "aaaa purga\n",
      "aaaa pasco\n",
      "aaaa <>robe\n",
      "aaaa robel\n",
      "aaaa belly\n",
      "aaaa <>xina\n",
      "aaaa <>irw\n",
      "aaaa <>irwi\n",
      "aaaa irwin\n",
      "aaaa hania\n",
      "aaaa <>few\n",
      "aaaa <>fewa\n",
      "aaaa <>fleg\n",
      "aaaa flege\n",
      "aaaa legel\n",
      "aaaa carri\n",
      "aaaa ferra\n",
      "aaaa errar\n",
      "aaaa <>halk\n",
      "aaaa halka\n",
      "aaaa <>eisb\n",
      "aaaa eisbr\n",
      "aaaa chell\n",
      "aaaa <>uso\n",
      "aaaa <>mek\n",
      "aaaa <>mekk\n",
      "aaaa mekki\n",
      "aaaa <>faim\n",
      "aaaa faime\n",
      "aaaa <>klin\n",
      "aaaa klint\n",
      "aaaa <>heru\n",
      "aaaa herul\n",
      "aaaa erulf\n",
      "aaaa <>eyco\n",
      "aaaa <>bobe\n",
      "aaaa bobek\n",
      "aaaa annes\n",
      "aaaa <>mark\n",
      "aaaa crisc\n",
      "aaaa debay\n",
      "aaaa ecili\n",
      "aaaa jessa\n",
      "aaaa blues\n",
      "aaaa <>darw\n",
      "aaaa darwi\n",
      "aaaa <>sly\n",
      "aaaa zando\n",
      "aaaa matok\n",
      "aaaa zoppo\n",
      "aaaa ismae\n",
      "aaaa smael\n",
      "aaaa <>pyrr\n",
      "aaaa pyrrh\n",
      "aaaa yrrhu\n",
      "aaaa rrhus\n",
      "aaaa shada\n",
      "aaaa uasti\n",
      "aaaa carib\n",
      "aaaa aribo\n",
      "aaaa ribou\n",
      "aaaa benjo\n",
      "aaaa berix\n",
      "aaaa <>boya\n",
      "aaaa <>rany\n",
      "aaaa <>uka\n",
      "aaaa <>tedd\n",
      "aaaa teddy\n",
      "aaaa <>epp\n",
      "aaaa <>eppo\n",
      "aaaa <>iffo\n",
      "aaaa heria\n",
      "aaaa arill\n",
      "aaaa <>velt\n",
      "aaaa velta\n",
      "aaaa eltan\n",
      "aaaa gunna\n",
      "aaaa unnar\n",
      "aaaa <>sadd\n",
      "aaaa saddy\n",
      "aaaa <>gree\n",
      "aaaa green\n",
      "aaaa alban\n",
      "aaaa <>dusc\n",
      "aaaa dusch\n",
      "aaaa mindy\n",
      "aaaa <>anai\n",
      "aaaa anais\n",
      "aaaa darle\n",
      "aaaa rleen\n",
      "aaaa <>inde\n",
      "aaaa ndera\n",
      "aaaa ophie\n",
      "aaaa <>pfe\n",
      "aaaa <>pfei\n",
      "aaaa pfeil\n",
      "aaaa feilo\n",
      "aaaa urano\n",
      "aaaa <>bega\n",
      "aaaa ercur\n",
      "aaaa rcuri\n",
      "aaaa <>dono\n",
      "aaaa donol\n",
      "aaaa onolo\n",
      "aaaa nolon\n",
      "aaaa olons\n",
      "aaaa ajora\n",
      "aaaa jorat\n",
      "aaaa <>aok\n",
      "aaaa <>kaja\n",
      "aaaa <>bilb\n",
      "aaaa bilbo\n",
      "aaaa nkerb\n",
      "aaaa kerbe\n",
      "aaaa erbel\n",
      "aaaa rbell\n",
      "aaaa <>korb\n",
      "aaaa korbe\n",
      "aaaa orbel\n",
      "aaaa <>aar\n",
      "aaaa <>aaro\n",
      "aaaa aaron\n",
      "aaaa arsha\n",
      "aaaa rshal\n",
      "aaaa <>heyk\n",
      "aaaa heyko\n",
      "aaaa indio\n",
      "aaaa <>hets\n",
      "aaaa batis\n",
      "aaaa atist\n",
      "aaaa <>hulo\n",
      "aaaa hulot\n",
      "aaaa oblem\n",
      "aaaa blema\n",
      "aaaa madeu\n",
      "aaaa adeus\n",
      "aaaa <>game\n",
      "aaaa gameb\n",
      "aaaa amebo\n",
      "aaaa quixo\n",
      "aaaa uixot\n",
      "aaaa ixote\n",
      "aaaa geori\n",
      "aaaa eorin\n",
      "aaaa hivit\n",
      "aaaa ivita\n",
      "aaaa <>youm\n",
      "aaaa youme\n",
      "aaaa oumen\n",
      "aaaa <>kyro\n",
      "aaaa kyros\n",
      "aaaa ricot\n",
      "aaaa icott\n",
      "aaaa <>eloy\n",
      "aaaa <>mein\n",
      "aaaa meino\n",
      "aaaa micha\n",
      "aaaa <>gabi\n",
      "aaaa <>baus\n",
      "aaaa bausc\n",
      "aaaa ausch\n",
      "aaaa <>tyc\n",
      "aaaa <>tyco\n",
      "aaaa tycoo\n",
      "aaaa ycoon\n",
      "aaaa urenc\n",
      "aaaa istel\n",
      "aaaa arnab\n",
      "aaaa rnaby\n",
      "aaaa maite\n",
      "aaaa <>lint\n",
      "aaaa lintu\n",
      "aaaa raldi\n",
      "aaaa <>bah\n",
      "aaaa <>baha\n",
      "aaaa baham\n",
      "aaaa ahama\n",
      "aaaa kaira\n",
      "aaaa perid\n",
      "aaaa erido\n",
      "aaaa ridor\n",
      "aaaa filon\n",
      "aaaa <>kero\n",
      "aaaa aldur\n",
      "aaaa dacom\n",
      "aaaa grimo\n",
      "aaaa raola\n",
      "aaaa delic\n",
      "aaaa <>birg\n",
      "aaaa birge\n",
      "aaaa irger\n",
      "aaaa <>ront\n",
      "aaaa rontu\n",
      "aaaa sassa\n",
      "aaaa mochi\n",
      "aaaa ochit\n",
      "aaaa chito\n",
      "aaaa quaxi\n",
      "aaaa <>ayd\n",
      "aaaa <>ayda\n",
      "aaaa illip\n",
      "aaaa <>ceda\n",
      "aaaa cedan\n",
      "aaaa edanc\n",
      "aaaa <>birt\n",
      "aaaa birth\n",
      "aaaa irthe\n",
      "aaaa <>asg\n",
      "aaaa <>asga\n",
      "aaaa asgad\n",
      "aaaa <>goof\n",
      "aaaa goofy\n",
      "aaaa shara\n",
      "aaaa <>jarl\n",
      "aaaa jarla\n",
      "aaaa <>ciw\n",
      "aaaa <>ciwi\n",
      "aaaa inkar\n",
      "aaaa dding\n",
      "aaaa dingt\n",
      "aaaa nrica\n",
      "aaaa <>clow\n",
      "aaaa clown\n",
      "aaaa <>arne\n",
      "aaaa milly\n",
      "aaaa zenon\n",
      "aaaa <>klr\n",
      "aaaa <>klrc\n",
      "aaaa klrch\n",
      "aaaa snowl\n",
      "aaaa nowly\n",
      "aaaa jeana\n",
      "aaaa <>ich\n",
      "aaaa <>ichy\n",
      "aaaa ndora\n",
      "aaaa <>carn\n",
      "aaaa carne\n",
      "aaaa arnel\n",
      "aaaa <>veld\n",
      "aaaa velda\n",
      "aaaa <>pika\n",
      "aaaa pikac\n",
      "aaaa ikach\n",
      "aaaa kachu\n",
      "aaaa <>tuts\n",
      "aaaa tutsc\n",
      "aaaa <>jara\n",
      "aaaa hamil\n",
      "aaaa amilt\n",
      "aaaa milto\n",
      "aaaa ilton\n",
      "aaaa <>niz\n",
      "aaaa <>nizz\n",
      "aaaa nizza\n",
      "aaaa meria\n",
      "aaaa erian\n",
      "aaaa <>flye\n",
      "aaaa flyer\n",
      "aaaa lavia\n",
      "aaaa <>zenz\n",
      "aaaa zenzi\n",
      "aaaa <>katt\n",
      "aaaa katty\n",
      "aaaa <>sheb\n",
      "aaaa sheba\n",
      "aaaa <>boya\n",
      "aaaa boyar\n",
      "aaaa katra\n",
      "aaaa cherl\n",
      "aaaa <>kurb\n",
      "aaaa kurby\n",
      "aaaa <>gae\n",
      "aaaa <>gael\n",
      "aaaa gaeli\n",
      "aaaa aelic\n",
      "aaaa <>dru\n",
      "aaaa <>drum\n",
      "aaaa drumm\n",
      "aaaa rumme\n",
      "aaaa marta\n",
      "aaaa <>tesa\n",
      "aaaa siman\n",
      "aaaa balth\n",
      "aaaa altha\n",
      "aaaa lthas\n",
      "aaaa thasa\n",
      "aaaa ssilo\n",
      "aaaa <>betu\n",
      "aaaa betun\n",
      "aaaa etuna\n",
      "aaaa molly\n",
      "aaaa oscho\n",
      "aaaa alari\n",
      "aaaa laric\n",
      "aaaa arich\n",
      "aaaa <>mupp\n",
      "aaaa muppe\n",
      "aaaa uppet\n",
      "aaaa attri\n",
      "aaaa ttrix\n",
      "aaaa <>leop\n",
      "aaaa leopo\n",
      "aaaa eopol\n",
      "aaaa opold\n",
      "aaaa <>olaf\n",
      "aaaa aball\n",
      "aaaa llero\n",
      "aaaa manue\n",
      "aaaa anuel\n",
      "aaaa <>silo\n",
      "aaaa silor\n",
      "aaaa ilora\n",
      "aaaa katie\n",
      "aaaa <>mere\n",
      "aaaa meret\n",
      "aaaa ginse\n",
      "aaaa insen\n",
      "aaaa nseng\n",
      "aaaa miela\n",
      "aaaa <>wasi\n",
      "aaaa wasil\n",
      "aaaa <>nih\n",
      "aaaa <>niha\n",
      "aaaa nihal\n",
      "aaaa <>mexi\n",
      "aaaa mexic\n",
      "aaaa exico\n",
      "aaaa <>klif\n",
      "aaaa kliff\n",
      "aaaa <>sess\n",
      "aaaa sessy\n",
      "aaaa <>myla\n",
      "aaaa mylad\n",
      "aaaa rnolo\n",
      "aaaa ngolf\n",
      "aaaa condu\n",
      "aaaa ondur\n",
      "aaaa <>ecc\n",
      "aaaa <>ecco\n",
      "aaaa rinze\n",
      "aaaa inzes\n",
      "aaaa nzess\n",
      "aaaa <>hase\n",
      "aaaa <>lyko\n",
      "aaaa lykos\n",
      "aaaa <>nobe\n",
      "aaaa nobel\n",
      "aaaa cappo\n",
      "aaaa falka\n",
      "aaaa pasch\n",
      "aaaa onkin\n",
      "aaaa <>tyc\n",
      "aaaa <>tych\n",
      "aaaa tyche\n",
      "aaaa anluk\n",
      "aaaa nluka\n",
      "aaaa nderc\n",
      "aaaa derco\n",
      "aaaa ercov\n",
      "aaaa rcove\n",
      "aaaa cover\n",
      "aaaa zeppe\n",
      "aaaa ppeli\n",
      "aaaa pelin\n",
      "aaaa <>roxy\n",
      "aaaa <>drw\n",
      "aaaa <>drwh\n",
      "aaaa drwho\n",
      "aaaa tenno\n",
      "aaaa <>bant\n",
      "aaaa bantj\n",
      "aaaa <>gigi\n",
      "aaaa <>pamp\n",
      "aaaa pampf\n",
      "aaaa ampfi\n",
      "aaaa solin\n",
      "aaaa <>figo\n",
      "aaaa enjoy\n",
      "aaaa arano\n",
      "aaaa <>vrod\n",
      "aaaa vrodo\n",
      "aaaa <>onko\n",
      "aaaa <>patn\n",
      "aaaa patna\n",
      "aaaa alifo\n",
      "aaaa lifor\n",
      "aaaa iforn\n",
      "aaaa forni\n",
      "aaaa ornia\n",
      "aaaa <>epi\n",
      "aaaa <>epic\n",
      "aaaa <>jimm\n",
      "aaaa jimmy\n",
      "aaaa <>natj\n",
      "aaaa natja\n",
      "aaaa scrub\n",
      "aaaa crubb\n",
      "aaaa rubby\n",
      "aaaa <>quij\n",
      "aaaa quija\n",
      "aaaa brisa\n",
      "aaaa mandy\n",
      "aaaa <>oci\n",
      "aaaa <>ocia\n",
      "aaaa ocian\n",
      "aaaa <>wasc\n",
      "aaaa wasca\n",
      "aaaa <>kaf\n",
      "aaaa <>kafk\n",
      "aaaa kafka\n",
      "aaaa <>lalo\n",
      "aaaa lalos\n",
      "aaaa clare\n",
      "aaaa laren\n",
      "aaaa arenc\n",
      "aaaa <>kav\n",
      "aaaa <>kavi\n",
      "aaaa kavik\n",
      "aaaa <>usso\n",
      "aaaa chipa\n",
      "aaaa <>lib\n",
      "aaaa <>libe\n",
      "aaaa liber\n",
      "aaaa ibert\n",
      "aaaa berty\n",
      "aaaa pring\n",
      "aaaa gimpo\n",
      "aaaa <>bed\n",
      "aaaa <>bedl\n",
      "aaaa bedla\n",
      "aaaa aureg\n",
      "aaaa urega\n",
      "aaaa regar\n",
      "aaaa egard\n",
      "aaaa <>vele\n",
      "aaaa veled\n",
      "aaaa eleda\n",
      "aaaa <>ubu\n",
      "aaaa <>kyri\n",
      "aaaa kyril\n",
      "aaaa <>adiy\n",
      "aaaa adiya\n",
      "aaaa diyat\n",
      "aaaa iyath\n",
      "aaaa <>bimb\n",
      "aaaa bimbo\n",
      "aaaa <>wico\n",
      "aaaa peril\n",
      "aaaa erill\n",
      "aaaa ulinc\n",
      "aaaa linch\n",
      "aaaa matil\n",
      "aaaa atild\n",
      "aaaa tilda\n",
      "aaaa siopa\n",
      "aaaa iopai\n",
      "aaaa opaia\n",
      "aaaa <>heda\n",
      "aaaa <>trim\n",
      "aaaa trimm\n",
      "aaaa rimmi\n",
      "aaaa armas\n",
      "aaaa <>elca\n",
      "aaaa elcan\n",
      "aaaa <>hulk\n",
      "aaaa <>mark\n",
      "aaaa marko\n",
      "aaaa <>summ\n",
      "aaaa summi\n",
      "aaaa ummit\n",
      "aaaa muddl\n",
      "aaaa <>yr\n",
      "aaaa <>yra\n",
      "aaaa <>husc\n",
      "aaaa <>digg\n",
      "aaaa digge\n",
      "aaaa <>karr\n",
      "aaaa karra\n",
      "aaaa <>eile\n",
      "aaaa eilee\n",
      "aaaa <>summ\n",
      "aaaa summe\n",
      "aaaa ileys\n",
      "aaaa zotti\n",
      "aaaa <>wenj\n",
      "aaaa wenja\n",
      "aaaa <>thil\n",
      "aaaa thilo\n",
      "aaaa <>chey\n",
      "aaaa cheye\n",
      "aaaa heyen\n",
      "aaaa eyenn\n",
      "aaaa <>arnd\n",
      "aaaa arndt\n",
      "aaaa <>fera\n",
      "aaaa barko\n",
      "aaaa <>tick\n",
      "aaaa ticke\n",
      "aaaa taran\n",
      "aaaa rantu\n",
      "aaaa antul\n",
      "aaaa ntull\n",
      "aaaa tulla\n",
      "aaaa unity\n",
      "aaaa <>hood\n",
      "aaaa <>eudi\n",
      "aaaa eudic\n",
      "aaaa udice\n",
      "aaaa whisp\n",
      "aaaa hispe\n",
      "aaaa <>both\n",
      "aaaa botho\n",
      "aaaa othok\n",
      "aaaa thoka\n",
      "aaaa hokai\n",
      "aaaa <>nomi\n",
      "aaaa <>luca\n",
      "aaaa <>urb\n",
      "aaaa <>urba\n",
      "aaaa urban\n",
      "aaaa <>rein\n",
      "aaaa reina\n",
      "aaaa hibbi\n",
      "aaaa yrano\n",
      "aaaa <>pez\n",
      "aaaa <>pezz\n",
      "aaaa pezzi\n",
      "aaaa <>ninj\n",
      "aaaa ninja\n",
      "aaaa <>ganj\n",
      "aaaa ganja\n",
      "aaaa dally\n",
      "aaaa <>dean\n",
      "aaaa <>finl\n",
      "aaaa finle\n",
      "aaaa inley\n",
      "aaaa easym\n",
      "aaaa asymo\n",
      "aaaa symon\n",
      "aaaa ymone\n",
      "aaaa money\n",
      "aaaa <>kau\n",
      "aaaa <>kauk\n",
      "aaaa kauka\n",
      "aaaa aukas\n",
      "aaaa ukasu\n",
      "aaaa kasus\n",
      "aaaa rinze\n",
      "aaaa inzes\n",
      "aaaa nzess\n",
      "aaaa zessi\n",
      "aaaa shaky\n",
      "aaaa orcus\n",
      "aaaa <>ritc\n",
      "aaaa ritch\n",
      "aaaa itchi\n",
      "aaaa tchie\n",
      "aaaa ejant\n",
      "aaaa janto\n",
      "aaaa darco\n",
      "aaaa eskim\n",
      "aaaa skimo\n",
      "aaaa tomme\n",
      "aaaa ommes\n",
      "aaaa rrosa\n",
      "aaaa finou\n",
      "aaaa mannu\n",
      "aaaa chora\n",
      "aaaa <>papo\n",
      "aaaa papoo\n",
      "aaaa apoos\n",
      "aaaa poose\n",
      "aaaa genni\n",
      "aaaa heily\n",
      "aaaa <>orma\n",
      "aaaa <>cato\n",
      "aaaa chani\n",
      "aaaa shalo\n",
      "aaaa <>marr\n",
      "aaaa <>lasc\n",
      "aaaa lasco\n",
      "aaaa <>pitc\n",
      "aaaa pitch\n",
      "aaaa itchu\n",
      "aaaa amesd\n",
      "aaaa mesde\n",
      "aaaa esdea\n",
      "aaaa sdean\n",
      "aaaa ursul\n",
      "aaaa rsula\n",
      "aaaa lanko\n",
      "aaaa <>tork\n",
      "aaaa torko\n",
      "aaaa <>kunz\n",
      "aaaa <>sint\n",
      "aaaa sinta\n",
      "aaaa <>ivy\n",
      "aaaa <>nama\n",
      "aaaa namac\n",
      "aaaa amacu\n",
      "aaaa ldusa\n",
      "aaaa zamba\n",
      "aaaa nicor\n",
      "aaaa njana\n",
      "Total perplexity: 6101.849071725879\n",
      "Mean perplexity: 12.845998045738693\n"
     ]
    }
   ],
   "source": [
    "# Test set perplexity\n",
    "n = 6\n",
    "ngrams = ngram_list_updated(names_train, n)\n",
    "counts= ngram_count(ngrams)\n",
    "firsts, nexts, probabilities = calculate_conditional_probabilities(counts)\n",
    "perplexities = calculate_test_set_perplexities(names_test, probabilities, n)\n",
    "print(f\"Total perplexity: {sum(perplexities)}\")\n",
    "print(f\"Mean perplexity: {sum(perplexities)/len(perplexities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefead3",
   "metadata": {},
   "source": [
    "# Word generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = generate_words(1000, firsts, nexts, probabilities, n)\n",
    "print(f\"% of words generated that are also in train set: {len(set(words).intersection(set(names_train)))/len(set(words))}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = \", \".join(list(set(words) - set(names_train))[0:10])\n",
    "print(f\"Examples of new words: {new_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in names if \"agnolia\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d098f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charlm",
   "language": "python",
   "name": "charlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
